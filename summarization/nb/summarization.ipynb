{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4721e7-b371-4949-abb4-3670f54cb388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing all the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7328b6f2-8ba7-4fc6-8784-1848e7e996b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./virtual3/lib/python3.13/site-packages (25.0.1)\n",
      "Looking in indexes: https://download.pytorch.org/whl/torchstable.html\n",
      "Requirement already satisfied: torch in ./virtual3/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in ./virtual3/lib/python3.13/site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in ./virtual3/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in ./virtual3/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./virtual3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./virtual3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./virtual3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./virtual3/lib/python3.13/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in ./virtual3/lib/python3.13/site-packages (from torch) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./virtual3/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./virtual3/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in ./virtual3/lib/python3.13/site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./virtual3/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./virtual3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: transformers in ./virtual3/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: datasets in ./virtual3/lib/python3.13/site-packages (3.4.0)\n",
      "Requirement already satisfied: rouge-score in ./virtual3/lib/python3.13/site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in ./virtual3/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./virtual3/lib/python3.13/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./virtual3/lib/python3.13/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./virtual3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./virtual3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./virtual3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./virtual3/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./virtual3/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./virtual3/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./virtual3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./virtual3/lib/python3.13/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./virtual3/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./virtual3/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in ./virtual3/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./virtual3/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in ./virtual3/lib/python3.13/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in ./virtual3/lib/python3.13/site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: absl-py in ./virtual3/lib/python3.13/site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: nltk in ./virtual3/lib/python3.13/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in ./virtual3/lib/python3.13/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./virtual3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./virtual3/lib/python3.13/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./virtual3/lib/python3.13/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./virtual3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./virtual3/lib/python3.13/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: click in ./virtual3/lib/python3.13/site-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in ./virtual3/lib/python3.13/site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./virtual3/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./virtual3/lib/python3.13/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./virtual3/lib/python3.13/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in ./virtual3/lib/python3.13/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./virtual3/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./virtual3/lib/python3.13/site-packages (from accelerate>=0.26.0) (24.2)\n",
      "Requirement already satisfied: psutil in ./virtual3/lib/python3.13/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in ./virtual3/lib/python3.13/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./virtual3/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./virtual3/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.29.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./virtual3/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in ./virtual3/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./virtual3/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in ./virtual3/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./virtual3/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./virtual3/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./virtual3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./virtual3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in ./virtual3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./virtual3/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./virtual3/lib/python3.13/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./virtual3/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./virtual3/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./virtual3/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./virtual3/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./virtual3/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n",
      "Requirement already satisfied: evaluate in ./virtual3/lib/python3.13/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./virtual3/lib/python3.13/site-packages (from evaluate) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./virtual3/lib/python3.13/site-packages (from evaluate) (2.2.4)\n",
      "Requirement already satisfied: dill in ./virtual3/lib/python3.13/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./virtual3/lib/python3.13/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./virtual3/lib/python3.13/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./virtual3/lib/python3.13/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./virtual3/lib/python3.13/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./virtual3/lib/python3.13/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./virtual3/lib/python3.13/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./virtual3/lib/python3.13/site-packages (from evaluate) (0.29.3)\n",
      "Requirement already satisfied: packaging in ./virtual3/lib/python3.13/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in ./virtual3/lib/python3.13/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./virtual3/lib/python3.13/site-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: aiohttp in ./virtual3/lib/python3.13/site-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./virtual3/lib/python3.13/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./virtual3/lib/python3.13/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./virtual3/lib/python3.13/site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./virtual3/lib/python3.13/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./virtual3/lib/python3.13/site-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./virtual3/lib/python3.13/site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./virtual3/lib/python3.13/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./virtual3/lib/python3.13/site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./virtual3/lib/python3.13/site-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./virtual3/lib/python3.13/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in ./virtual3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: protobuf in ./virtual3/lib/python3.13/site-packages (6.30.1)\n",
      "Requirement already satisfied: sentencepiece in ./virtual3/lib/python3.13/site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy in ./virtual3/lib/python3.13/site-packages (2.2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/torchstable.html\n",
    "!pip install transformers datasets rouge-score\n",
    "!pip install --upgrade \"accelerate>=0.26.0\"\n",
    "!pip install evaluate\n",
    "!pip install protobuf\n",
    "!pip install sentencepiece\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a6221c-2732-408d-bd3b-8ebd0d91c215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading data\n",
    "df = pd.read_csv('data/Reviews.csv')\n",
    "\n",
    "# Checking data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f83ee4-4444-4c38-8338-fad1913b6b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text                summary\n",
       "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
       "2  This is a confection that has been around a fe...  \"Delight\" says it all"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns that we're going to keep\n",
    "df = df.rename(columns={\n",
    "    'Text': 'review_text', \n",
    "    'Summary': 'summary'\n",
    "})\n",
    "\n",
    "# Keeping only concerned columns\n",
    "df = df[['review_text', 'summary']]\n",
    "\n",
    "# Making sure all worked well\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "065f3371-9074-4aa9-aa2f-d3199e273e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows where either field is NaN\n",
    "df = df.dropna(subset=[\"review_text\", \"summary\"])\n",
    "\n",
    "# Casting them to strings\n",
    "df[\"review_text\"] = df[\"review_text\"].astype(str)\n",
    "df[\"summary\"] = df[\"summary\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a88d25e-2a74-483d-a293-b70dfd82f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_text                summary\n",
      "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
      "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
      "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
      "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
      "4  Great taffy at a great price.  There was a wid...            Great taffy\n",
      "review_text\n",
      "<class 'str'>    568427\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[[\"review_text\", \"summary\"]].head())\n",
    "print(df[\"review_text\"].apply(type).value_counts())  # Ensure everything is <class 'str'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a4a76d-be8d-4922-8ac1-0aa42624dfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41434</th>\n",
       "      <td>These are actually very tasty.  Pure potatoes ...</td>\n",
       "      <td>I like these!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209481</th>\n",
       "      <td>I realize that taste is a matter of personal p...</td>\n",
       "      <td>Good but subjectively not 5 star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247306</th>\n",
       "      <td>This is one of my Favorite cup of soup choices...</td>\n",
       "      <td>Lipton Cup A Soup, Spring Vegetable.4 oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80089</th>\n",
       "      <td>If you like the classic taste of a good margar...</td>\n",
       "      <td>Suited to its purpose, if not quite its goal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218580</th>\n",
       "      <td>I was willing to give this a chance even after...</td>\n",
       "      <td>Tastes artificial!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review_text  \\\n",
       "41434   These are actually very tasty.  Pure potatoes ...   \n",
       "209481  I realize that taste is a matter of personal p...   \n",
       "247306  This is one of my Favorite cup of soup choices...   \n",
       "80089   If you like the classic taste of a good margar...   \n",
       "218580  I was willing to give this a chance even after...   \n",
       "\n",
       "                                                summary  \n",
       "41434                                     I like these!  \n",
       "209481                 Good but subjectively not 5 star  \n",
       "247306         Lipton Cup A Soup, Spring Vegetable.4 oz  \n",
       "80089   Suited to its purpose, if not quite its goal...  \n",
       "218580                               Tastes artificial!  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 1000 #due to memory constraints on local machines, we're cutting down the data to 1000 rows for validation before we explore other ideas on how to scale\n",
    "df_sampled = df.sample(n=min(n_samples, len(df)), random_state=42)\n",
    "\n",
    "df_sampled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53714712-e3a6-4c71-b8de-e18ecfa662b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['review_text', 'summary', '__index_level_0__'],\n",
      "    num_rows: 700\n",
      "})\n",
      "Dataset({\n",
      "    features: ['review_text', 'summary', '__index_level_0__'],\n",
      "    num_rows: 300\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Convert the entire dataframe to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df_sampled)\n",
    "\n",
    "# Train/Test Split\n",
    "# Doing a 90% train, 10% test split\n",
    "dataset_split = dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train_dataset = dataset_split[\"train\"]\n",
    "test_dataset  = dataset_split[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac953fd5-7463-41a0-a9d5-8ef0d9c91184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                                               | 0/700 [00:00<?, ? examples/s]/Users/aakashsondhi/Desktop/Projects/amazonfinefood-main/virtual3/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████████████████████████████| 700/700 [00:00<00:00, 5173.01 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████| 300/300 [00:00<00:00, 5284.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"google/t5-small-ssm-nq\"  # \"t5-small\", \"t5-base\", will be our next choice.\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Defining our preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"summarize: \" + ex for ex in examples[\"review_text\"]]\n",
    "    targets = examples[\"summary\"]\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=True  # Add explicit padding\n",
    "    )\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=64,\n",
    "            truncation=True,\n",
    "            padding=True  # Add padding for targets\n",
    "        )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test  = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54dddda6-715e-4d3f-910c-a6fae828d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl #had issues installing nltk on the mac so a suggested solution online was to import ssl and attempt below try else code.\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f37d5f5-fba2-4431-ae4d-7139c8127e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aakashsondhi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2eb55a7-567b-4572-9df8-5d5021f95640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aakashsondhi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/aakashsondhi/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "Map:   0%|                                                               | 0/700 [00:00<?, ? examples/s]/Users/aakashsondhi/Desktop/Projects/amazonfinefood-main/virtual3/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3970: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|███████████████████████████████████████████████████| 700/700 [00:00<00:00, 6153.47 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████| 300/300 [00:00<00:00, 5600.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1050/1050 09:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.269900</td>\n",
       "      <td>0.730053</td>\n",
       "      <td>1.382300</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>1.271000</td>\n",
       "      <td>1.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.058600</td>\n",
       "      <td>0.705922</td>\n",
       "      <td>1.432300</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>1.267300</td>\n",
       "      <td>1.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.106900</td>\n",
       "      <td>0.702623</td>\n",
       "      <td>1.448000</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>1.355500</td>\n",
       "      <td>1.366500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1050, training_loss=1.4965096500941686, metrics={'train_runtime': 597.2576, 'train_samples_per_second': 3.516, 'train_steps_per_second': 1.758, 'total_flos': 142108891545600.0, 'train_loss': 1.4965096500941686, 'epoch': 3.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    T5Tokenizer, \n",
    "    T5ForConditionalGeneration, \n",
    "    DataCollatorForSeq2Seq, \n",
    "    Seq2SeqTrainingArguments, \n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "# downloading required nltk packages\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# attempting to utilize apple silicon's mps which is gpu equivalent by utilizing torch's mps feature\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "#model_name = \"google/t5-small-ssm-nq\" a model tried earlier that yield poor results\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Workarounds added after system errors around using t5\n",
    "model.config.use_cache = False\n",
    "# Explicitly setting the decoder start token\n",
    "model.config.decoder_start_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Preprocessing function \n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"summarize: \" + ex for ex in examples[\"review_text\"]]\n",
    "    targets = examples[\"summary\"]\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize targets in target mode\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=64,\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the datasets \n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test  = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Loading ROUGE metric\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Moving predictions/labels to CPU and converting them to lists\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.cpu().tolist()\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().tolist()\n",
    "\n",
    "    # Throwing out invalid token IDs in predictions\n",
    "    predictions = [\n",
    "        [token if 0 <= token < tokenizer.vocab_size else tokenizer.pad_token_id for token in seq]\n",
    "        for seq in predictions\n",
    "    ]\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replacing -100 in labels with pad token id so they can be decoded\n",
    "    labels = [\n",
    "        [token if token != -100 else tokenizer.pad_token_id for token in seq]\n",
    "        for seq in labels\n",
    "    ]\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # ROUGE expects a new line after each sentence, so tokenizing with nltk\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = rouge_metric.compute(\n",
    "        predictions=decoded_preds,\n",
    "        references=decoded_labels,\n",
    "        use_stemmer=True\n",
    "    )\n",
    "\n",
    "    # Formating the scores as percentages\n",
    "    return {k: round(v * 100, 4) for k, v in result.items()}\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    "    label_pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_summarization_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    # gradient_accumulation_steps=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=64,\n",
    "    generation_num_beams=1 \n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Begin training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb63daf-ed73-49df-ae7f-d5e3ee6ba77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Args No 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab8af9-a663-49a6-a176-3101af17e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_summarization_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    # gradient_accumulation_steps=2, \n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=64,\n",
    "    generation_num_beams=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec01d666-1898-433f-a79d-8be704c13c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Args No.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40463a1e-12d2-48b0-9874-33416b24034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"my_summarization_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    #gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=64,\n",
    "    generation_num_beams=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
